{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9367df",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "\n",
    "* Semantic chunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "* It ensures that each chunk is semantically coherent and not cut off mid-thought like traditional character/token splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d0704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is a framework for building applications with LLMs.',\n",
       " 'Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.',\n",
       " 'You can create chains, agents, memory and retrievers.',\n",
       " 'The Eiffel Tower is located in Paris.',\n",
       " 'France is a popular tourist destination.',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating sentences from given document\n",
    "\n",
    "with open(\"some_text.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "text\n",
    "\n",
    "sentences = [sentence.strip() for sentence in text.split(\"\\n\")]\n",
    "sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c94ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02109219, -0.04472181,  0.01087082, ..., -0.01217807,\n",
       "         0.0860565 ,  0.02890728],\n",
       "       [-0.03418018, -0.10210436,  0.00366995, ..., -0.01398788,\n",
       "         0.04454358,  0.0055136 ],\n",
       "       [-0.03057391, -0.05121858, -0.13566265, ...,  0.02557612,\n",
       "         0.07362268, -0.03177413],\n",
       "       [ 0.06605352,  0.03884843,  0.01661566, ...,  0.03093833,\n",
       "         0.07991004,  0.05157553],\n",
       "       [ 0.1040301 , -0.030977  ,  0.02524889, ...,  0.07805588,\n",
       "         0.01353773, -0.02684903],\n",
       "       [-0.11883845,  0.04829879, -0.00254817, ...,  0.12640947,\n",
       "         0.04654907, -0.01571721]], shape=(6, 384), dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get embeddings for those sentences\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "sentences_vectors = embedding_model.encode(sentences)\n",
    "sentences_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bffa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8263334]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(sentences_vectors[0].reshape(1, -1), sentences_vectors[3].reshape(1, -1))\n",
    "#cosine_similarity([sentences_vectors[0]], [sentences_vectors[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580cae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Semantic Chunks:\n",
      "\n",
      "Chunk 1:\n",
      " Langchain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      " You can create chains, agents, memory and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      " The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      " France is a popular tourist destination.\n",
      "\n",
      "Chunk 5:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#defining a function to compare cosine similarity between vectors and place them in same chunk\n",
    "threshold = 0.8\n",
    "chunks =[]\n",
    "current_chunk=[sentences[0]]\n",
    "for i in range(1, len(sentences)):\n",
    "    sim_score = cosine_similarity([sentences_vectors[i-1]], [sentences_vectors[i]])[0][0]\n",
    "    if sim_score >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk)) \n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "    #appedn the last chunk\n",
    "chunks.append(\" \". join(current_chunk))   \n",
    "\n",
    "#output the chunks\n",
    "print(\"\\n Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n {chunk}\")        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd16c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining class for this advanced semantic chunking\n",
    "\n",
    "class SemanticChunking:\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", threshold=0.8):\n",
    "        self.embedding = SentenceTransformer(model=model)\n",
    "        self.threshold = threshold\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGs In Depth (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
