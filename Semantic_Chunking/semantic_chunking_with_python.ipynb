{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9367df",
   "metadata": {},
   "source": [
    "### Semantic Chunking\n",
    "\n",
    "* Semantic chunker is a document splitter that uses embedding similarity between sentences to decide chunk boundaries.\n",
    "* It ensures that each chunk is semantically coherent and not cut off mid-thought like traditional character/token splitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d0704f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is a framework for building applications with LLMs.',\n",
       " 'Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.',\n",
       " 'You can create chains, agents, memory and retrievers.',\n",
       " 'The Eiffel Tower is located in Paris.',\n",
       " 'France is a popular tourist destination.',\n",
       " '']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating sentences from given document\n",
    "\n",
    "with open(\"some_text.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "text\n",
    "\n",
    "sentences = [sentence.strip() for sentence in text.split(\"\\n\")]\n",
    "sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c94ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02109219, -0.04472181,  0.01087082, ..., -0.01217807,\n",
       "         0.0860565 ,  0.02890728],\n",
       "       [-0.03418018, -0.10210436,  0.00366995, ..., -0.01398788,\n",
       "         0.04454358,  0.0055136 ],\n",
       "       [-0.03057391, -0.05121858, -0.13566265, ...,  0.02557612,\n",
       "         0.07362268, -0.03177413],\n",
       "       [ 0.06605352,  0.03884843,  0.01661566, ...,  0.03093833,\n",
       "         0.07991004,  0.05157553],\n",
       "       [ 0.1040301 , -0.030977  ,  0.02524889, ...,  0.07805588,\n",
       "         0.01353773, -0.02684903],\n",
       "       [-0.11883845,  0.04829879, -0.00254817, ...,  0.12640947,\n",
       "         0.04654907, -0.01571721]], shape=(6, 384), dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get embeddings for those sentences\n",
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "sentences_vectors = embedding_model.encode(sentences)\n",
    "sentences_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bffa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8263334]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(sentences_vectors[0].reshape(1, -1), sentences_vectors[3].reshape(1, -1))\n",
    "#cosine_similarity([sentences_vectors[0]], [sentences_vectors[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580cae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Semantic Chunks:\n",
      "\n",
      "Chunk 1:\n",
      " Langchain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
      "\n",
      "Chunk 2:\n",
      " You can create chains, agents, memory and retrievers.\n",
      "\n",
      "Chunk 3:\n",
      " The Eiffel Tower is located in Paris.\n",
      "\n",
      "Chunk 4:\n",
      " France is a popular tourist destination.\n",
      "\n",
      "Chunk 5:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#defining a function to compare cosine similarity between vectors and place them in same chunk\n",
    "threshold = 0.8\n",
    "chunks =[]\n",
    "current_chunk=[sentences[0]]\n",
    "for i in range(1, len(sentences)):\n",
    "    sim_score = cosine_similarity([sentences_vectors[i-1]], [sentences_vectors[i]])[0][0]\n",
    "    if sim_score >= threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk)) \n",
    "        current_chunk = [sentences[i]]\n",
    "\n",
    "    #appedn the last chunk\n",
    "chunks.append(\" \". join(current_chunk))   \n",
    "\n",
    "#output the chunks\n",
    "print(\"\\n Semantic Chunks:\")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}:\\n {chunk}\")        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdd16c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining class for this advanced semantic chunking\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class SemanticChunking:\n",
    "    def __init__(self, model=\"sentence-transformers/all-MiniLM-L6-v2\", threshold=0.8):\n",
    "        self.embedding = SentenceTransformer(model)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def chunk_splitter(self, file_path:str):\n",
    "\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text = file.read()\n",
    "\n",
    "        sentences = [sentence.strip() for sentence in text.split(\"\\n\")]\n",
    "        embeddings = self.embedding.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk=[sentences[0]]\n",
    "\n",
    "        for i in range(1,len(sentences)):\n",
    "            sim_score = cosine_similarity([embeddings[i]], [embeddings[i-1]])[0][0]\n",
    "\n",
    "            if sim_score > self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk =[sentences[i]]\n",
    "\n",
    "        chunks.append(\" \".join(current_chunk))  \n",
    "        return chunks\n",
    "    \n",
    "    def split_documents(self,file_path:str):\n",
    "        result = []\n",
    "        for idx, chunk in enumerate(self.chunk_splitter(file_path)):\n",
    "                result.append(Document(page_content=chunk, metadata={\"page\": idx}))\n",
    "        return result        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ecc72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SemanticChunking at 0x1d008ac50d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_chunking = SemanticChunking()\n",
    "semantic_chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58efa859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.',\n",
       " 'You can create chains, agents, memory and retrievers.',\n",
       " 'The Eiffel Tower is located in Paris.',\n",
       " 'France is a popular tourist destination.',\n",
       " '']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_chunks=semantic_chunking.chunk_splitter('some_text.txt')\n",
    "semantic_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6053bfce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 0}, page_content='Langchain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={'page': 1}, page_content='You can create chains, agents, memory and retrievers.'),\n",
       " Document(metadata={'page': 2}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={'page': 3}, page_content='France is a popular tourist destination.'),\n",
       " Document(metadata={'page': 4}, page_content='')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_docs = semantic_chunking.split_documents('some_text.txt')\n",
    "final_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3b4993d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x1d0119f4c50>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=semantic_chunking.split_documents('some_text.txt'),\n",
    "                                   embedding=HuggingFaceEmbeddings(model='all-MiniLM-L6-v2'))\n",
    "\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "af6ada78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d29020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the following question based on context.\\n    context: {context}\\n    question: {question}\\n    '), additional_kwargs={})])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template='''Answer the following question based on context.\n",
    "    context: {context}\n",
    "    question: {question}\n",
    "    '''\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ad62616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001D01514A310>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D01528AC90>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e00c2c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001D0119F4C50>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the following question based on context.\\n    context: {context}\\n    question: {question}\\n    '), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001D01514A310>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D01528AC90>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LCEL Chain with Retriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever ,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "     | prompt\n",
    "     | model\n",
    "     | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54e3ba70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Eiffel Tower is located in Paris, as stated in the document with id '879b4756-3315-4491-a5f1-a05c212460d4'.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"say about eiffle tower\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGs In Depth (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
