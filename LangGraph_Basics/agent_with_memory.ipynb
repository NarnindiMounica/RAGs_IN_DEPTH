{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8695f96",
   "metadata": {},
   "source": [
    "### Agent with Memory using MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c939aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4de0f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'd:\\\\RAGs In Depth\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " TavilySearch(max_results=3, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using tools provided by langchain\n",
    "\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=500))\n",
    "\n",
    "arxiv = ArxivQueryRun(api_wrapper= ArxivAPIWrapper(top_k_results=3, doc_content_chars_max=500))\n",
    "\n",
    "tavily= TavilySearch(max_results=3)\n",
    "\n",
    "tools=[wikipedia, arxiv, tavily]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59922939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000002AE0C384310>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002AE0C4D1D10>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'start_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or after this date.\\n        \\n        Use this parameter when you need to:\\n        - Find recent developments or updates on a topic\\n        - Exclude outdated information from search results\\n        - Focus on content within a specific timeframe\\n        - Combine with end_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-01-15\" for January 15, 2024).\\n        \\n        Examples:\\n        - \"2024-01-01\" - Results from January 1, 2024 onwards\\n        - \"2023-12-25\" - Results from December 25, 2023 onwards\\n        \\n        When combined with end_date, creates a precise date range filter.\\n        \\n        Default is None (no start date restriction).\\n        '}, 'end_date': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Filters search results to include only content published on or before this date.\\n        \\n        Use this parameter when you need to:\\n        - Exclude content published after a certain date\\n        - Study historical information or past events\\n        - Research how topics were covered during specific time periods\\n        - Combine with start_date to create a custom date range\\n        \\n        Format must be YYYY-MM-DD (e.g., \"2024-03-31\" for March 31, 2024).\\n        \\n        Examples:\\n        - \"2024-03-31\" - Results up to and including March 31, 2024\\n        - \"2023-12-31\" - Results up to and including December 31, 2023\\n        \\n        When combined with start_date, creates a precise date range filter.\\n        For example: start_date=\"2024-01-01\", end_date=\"2024-03-31\" \\n        returns results from Q1 2024 only.\\n        \\n        Default is None (no end date restriction).\\n        '}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tools binded chat model\n",
    "\n",
    "tools_model = init_chat_model(model=\"groq:llama-3.1-8b-instant\").bind_tools(tools)\n",
    "tools_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b71ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining state schema for graph\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0b369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node definition\n",
    "\n",
    "def model_node(state:State):\n",
    "    return {\"messages\": tools_model.invoke(state['messages'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6843ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002AE0BB6D910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#graph workflow\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"model_node\", model_node)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "graph.add_edge(START, \"model_node\")\n",
    "graph.add_conditional_edges(\"model_node\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"model_node\")\n",
    "graph.add_edge(\"model_node\", END)\n",
    "\n",
    "#memorysaver checkpointer\n",
    "\n",
    "memory= MemorySaver()\n",
    "\n",
    "graph_builder = graph.compile(checkpointer=memory)\n",
    "graph_builder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d418c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "give 3 latest ai news\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (gsj8r4zym)\n",
      " Call ID: gsj8r4zym\n",
      "  Args:\n",
      "    query: latest AI news\n",
      "    time_range: day\n",
      "    topic: news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"latest AI news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.foxnews.com/tech/ai-newsletter-blue-collar-productivity-boom\", \"title\": \"Fox News AI Newsletter: Blue-collar productivity boom - Fox News\", \"score\": 0.769306, \"published_date\": \"Fri, 19 Dec 2025 14:49:03 GMT\", \"content\": \"# Fox News AI Newsletter: Blue-collar productivity boom. ## **Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements.**. **RISE OF MACHINES:** Palantir Chief Technology Officer Shyam Sankar told FOX Business artificial intelligence is fueling a blue-collar productivity boom, not mass unemployment as forecast by Sen. Bernie Sanders, I-Vt. Sankar said AI is accelerating hiring, training and American industrial growth. **EYES TO THE FUTURE:** Artificial intelligence (AI) is charging into a new phase in 2026 – one that could reshape business operations, global competition and even which workers thrive, according to Goldman Sachs' Chief Information Officer Marco Argenti. **TECH FORCE:** The Trump administration launched a new initiative Monday aimed at recruiting top-tier technical talent to accelerate the adoption of artificial intelligence (AI) at the federal level. Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News here.\", \"raw_content\": null}, {\"url\": \"https://www.wsj.com/tech/ai/meta-developing-new-ai-image-and-video-model-code-named-mango-16e785c7?gaa_at=eafs&gaa_n=AWEtsqedh9LDNQw5sS8-iU5Xeanwk9kqFssswq4wASfuI_y4SRSKDh8ULFHx&gaa_ts=69447c18&gaa_sig=oRZKxTpqZtnpbnt3qqEogXGgYVUT5NEe6XsA88u_XzLMQvWNW54Ru1WFbnisbWUU5s7rxCG_e1HIIkD1ZQz3RA%3D%3D\", \"title\": \"Exclusive | Meta Developing New AI Image and Video Model Code-Named ‘Mango’ - The Wall Street Journal\", \"score\": 0.5602773, \"published_date\": \"Thu, 18 Dec 2025 21:48:00 GMT\", \"content\": \"This copy is for your personal, non-commercial use only. For non-personal use or to order multiple copies, please contact. https://www.wsj.com/tech/ai/meta-developing-new-ai-image-and-video-model-code-named-mango-16e785c7. # Meta Developing New AI Image and Video Model Code-Named ‘Mango’. ## Alexandr Wang, the company’s AI chief, said the new model will debut soon, along with a large language model dubbed Avocado. Meta Platforms META 2.30%increase; green up pointing triangle is developing a new image and video-focused AI model code-named Mango alongside the company’s next text-based large language model. Meta’s META 2.30%increase; green up pointing triangle chief AI officer Alexandr Wang talked about the artificial intelligence models in an internal company Q&A on Thursday with Chris Cox, Meta’s chief product officer, according to people who heard the remarks. As AI threatens to give an advantage to attackers, the man who built Google’s $5.4 billion Mandiant business is working to restore the balance. ### AI Chip Startup MetaX Leaps in Trading Debut. The new, productivity-focused GPT-5.2 model comes as the AI company faces increasing competition from Google and Anthropic.\", \"raw_content\": null}, {\"url\": \"https://adage.com/opinion/aa-pete-blackshaw-the-year-brands-learned-what-ai-really-thinks/\", \"title\": \"The year brands learned what AI really thinks - Ad Age\", \"score\": 0.5310884, \"published_date\": \"Fri, 19 Dec 2025 11:00:00 GMT\", \"content\": \"# The year brands learned what AI really thinks. December 19, 2025 06:00 AM EST. ## Featured Stories. How Gap’s AI chatbot broke character—what brands can learn from the high-tech retail assistant. Chatbot opportunities have advanced thanks to the rise of generative AI, but so have the risks that brands could encounter. Agency Brief—Tombras hires its first chief operating officer. Marketing winners and losers of the week. Behind Target’s sales struggles and consumer disconnect—how marketing could fuel a comeback.\", \"raw_content\": null}], \"response_time\": 0.26, \"request_id\": \"21593177-d321-4a9c-8c1a-e660935e4f0e\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (b2rvqnj0w)\n",
      " Call ID: b2rvqnj0w\n",
      "  Args:\n",
      "    query: latest AI news\n",
      "    time_range: day\n",
      "    topic: news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"latest AI news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.foxnews.com/tech/ai-newsletter-blue-collar-productivity-boom\", \"title\": \"Fox News AI Newsletter: Blue-collar productivity boom - Fox News\", \"score\": 0.769306, \"published_date\": \"Fri, 19 Dec 2025 14:49:03 GMT\", \"content\": \"# Fox News AI Newsletter: Blue-collar productivity boom. ## **Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements.**. **RISE OF MACHINES:** Palantir Chief Technology Officer Shyam Sankar told FOX Business artificial intelligence is fueling a blue-collar productivity boom, not mass unemployment as forecast by Sen. Bernie Sanders, I-Vt. Sankar said AI is accelerating hiring, training and American industrial growth. **EYES TO THE FUTURE:** Artificial intelligence (AI) is charging into a new phase in 2026 – one that could reshape business operations, global competition and even which workers thrive, according to Goldman Sachs' Chief Information Officer Marco Argenti. **TECH FORCE:** The Trump administration launched a new initiative Monday aimed at recruiting top-tier technical talent to accelerate the adoption of artificial intelligence (AI) at the federal level. Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News here.\", \"raw_content\": null}, {\"url\": \"https://www.wsj.com/tech/ai/meta-developing-new-ai-image-and-video-model-code-named-mango-16e785c7?gaa_at=eafs&gaa_n=AWEtsqedh9LDNQw5sS8-iU5Xeanwk9kqFssswq4wASfuI_y4SRSKDh8ULFHx&gaa_ts=69447c18&gaa_sig=oRZKxTpqZtnpbnt3qqEogXGgYVUT5NEe6XsA88u_XzLMQvWNW54Ru1WFbnisbWUU5s7rxCG_e1HIIkD1ZQz3RA%3D%3D\", \"title\": \"Exclusive | Meta Developing New AI Image and Video Model Code-Named ‘Mango’ - The Wall Street Journal\", \"score\": 0.5602773, \"published_date\": \"Thu, 18 Dec 2025 21:48:00 GMT\", \"content\": \"This copy is for your personal, non-commercial use only. For non-personal use or to order multiple copies, please contact. https://www.wsj.com/tech/ai/meta-developing-new-ai-image-and-video-model-code-named-mango-16e785c7. # Meta Developing New AI Image and Video Model Code-Named ‘Mango’. ## Alexandr Wang, the company’s AI chief, said the new model will debut soon, along with a large language model dubbed Avocado. Meta Platforms META 2.30%increase; green up pointing triangle is developing a new image and video-focused AI model code-named Mango alongside the company’s next text-based large language model. Meta’s META 2.30%increase; green up pointing triangle chief AI officer Alexandr Wang talked about the artificial intelligence models in an internal company Q&A on Thursday with Chris Cox, Meta’s chief product officer, according to people who heard the remarks. As AI threatens to give an advantage to attackers, the man who built Google’s $5.4 billion Mandiant business is working to restore the balance. ### AI Chip Startup MetaX Leaps in Trading Debut. The new, productivity-focused GPT-5.2 model comes as the AI company faces increasing competition from Google and Anthropic.\", \"raw_content\": null}, {\"url\": \"https://adage.com/opinion/aa-pete-blackshaw-the-year-brands-learned-what-ai-really-thinks/\", \"title\": \"The year brands learned what AI really thinks - Ad Age\", \"score\": 0.5310884, \"published_date\": \"Fri, 19 Dec 2025 11:00:00 GMT\", \"content\": \"# The year brands learned what AI really thinks. December 19, 2025 06:00 AM EST. ## Featured Stories. How Gap’s AI chatbot broke character—what brands can learn from the high-tech retail assistant. Chatbot opportunities have advanced thanks to the rise of generative AI, but so have the risks that brands could encounter. Agency Brief—Tombras hires its first chief operating officer. Marketing winners and losers of the week. Behind Target’s sales struggles and consumer disconnect—how marketing could fuel a comeback.\", \"raw_content\": null}], \"response_time\": 0.25, \"request_id\": \"153750f2-affa-4bb7-99c0-b5c0e18314cf\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (273favewc)\n",
      " Call ID: 273favewc\n",
      "  Args:\n",
      "    query: latest AI news\n",
      "    time_range: day\n",
      "    topic: news\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"latest AI news\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.foxnews.com/tech/ai-newsletter-blue-collar-productivity-boom\", \"title\": \"Fox News AI Newsletter: Blue-collar productivity boom - Fox News\", \"score\": 0.9764905, \"published_date\": \"Fri, 19 Dec 2025 14:49:03 GMT\", \"content\": \"# Fox News AI Newsletter: Blue-collar productivity boom. ## **Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements.**. **RISE OF MACHINES:** Palantir Chief Technology Officer Shyam Sankar told FOX Business artificial intelligence is fueling a blue-collar productivity boom, not mass unemployment as forecast by Sen. Bernie Sanders, I-Vt. Sankar said AI is accelerating hiring, training and American industrial growth. **EYES TO THE FUTURE:** Artificial intelligence (AI) is charging into a new phase in 2026 – one that could reshape business operations, global competition and even which workers thrive, according to Goldman Sachs' Chief Information Officer Marco Argenti. **TECH FORCE:** The Trump administration launched a new initiative Monday aimed at recruiting top-tier technical talent to accelerate the adoption of artificial intelligence (AI) at the federal level. Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News here.\", \"raw_content\": null}, {\"url\": \"https://ts2.tech/en/apple-stock-aapl-today-latest-news-analyst-forecasts-and-key-drivers-on-december-19-2025/\", \"title\": \"Apple Stock (AAPL) Today: Latest News, Analyst Forecasts, and Key Drivers on December 19, 2025 - ts2.tech\", \"score\": 0.9390248, \"published_date\": \"Fri, 19 Dec 2025 15:30:55 GMT\", \"content\": \"# Apple Stock (AAPL) Today: Latest News, Analyst Forecasts, and Key Drivers on December 19, 2025. Apple Inc. stock (NASDAQ: AAPL) is back in the spotlight on Friday, December 19, 2025, as investors weigh a fresh wave of Wall Street forecasts tied to Apple’s AI roadmap against intensifying global scrutiny of the App Store model. The most widely circulated “forecast” development feeding into Apple stock chatter is Morgan Stanley’s latest outlook, which includes a **price target raise to $315 (from $305)** and a continued overweight stance. * Apple’s own developer news notes an updated Apple Developer Program License Agreement (December 17, 2025), including language describing Apple’s right to **offset or recoup amounts owed** and updated terms for **iOS apps in Japan**, including alternative distribution and payments. 1. Apple Stock (AAPL) Today: Latest News, Analyst Forecasts, and Key Drivers on December 19, 2025. ### Apple Stock (AAPL) Today: Latest News, Analyst Forecasts, and Key Drivers on December 19, 2025.\", \"raw_content\": null}, {\"url\": \"https://www.engadget.com/ai/googles-notebooklm-introduces-data-tables-feature-225548565.html\", \"title\": \"Google’s NotebookLM introduces Data Tables feature - Engadget\", \"score\": 0.9059898, \"published_date\": \"Thu, 18 Dec 2025 22:55:48 GMT\", \"content\": \"## Trending:. * OpenAI just launched a ChatGPT app store. * Samsung's P9 microSD Express card drops to a record-low price. # Google’s NotebookLM introduces Data Tables feature. Google's latest addition to its NotebookLM artificial intelligence research platform is a feature called Data Tables. The tool can collect and synthesize information across multiple sources into a chart that can be exported to Google Sheets. All Pro and Ultra users will have access to the feature today, and Data Tables will roll out to all users over the coming weeks. In practice, Google suggested that Data Tables can be used to organize scattered notes, create price comparison charts or aggregate results from multiple research projects. The example of the interface shows the desired table components requested in natural language statements. Last month, Google added a Deep Research mode to NotebookLM. Deep Research was initially unveiled for its Gemini chatbot in late 2024 as an option for handling complex user queries.\", \"raw_content\": null}], \"response_time\": 0.27, \"request_id\": \"462938ca-aa3b-4016-b348-902ca8aa4a92\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The latest AI news includes:\n",
      "\n",
      "1. Palantir Chief Technology Officer Shyam Sankar told FOX Business that artificial intelligence is fueling a blue-collar productivity boom, not mass unemployment as forecast by Sen. Bernie Sanders, I-Vt.\n",
      "2. Meta is developing a new image and video-focused AI model code-named Mango alongside the company's next text-based large language model.\n",
      "3. Apple's stock (AAPL) is back in the spotlight on Friday, December 19, 2025, as investors weigh a fresh wave of Wall Street forecasts tied to Apple’s AI roadmap against intensifying global scrutiny of the App Store model.\n",
      "4. Google's NotebookLM introduces Data Tables feature, a tool that can collect and synthesize information across multiple sources into a chart that can be exported to Google Sheets.\n",
      "\n",
      "These articles provide an overview of the latest developments in AI technology, including the impact of AI on the workforce, advancements in AI model development, and the integration of AI in various industries.\n"
     ]
    }
   ],
   "source": [
    "query=\"give 3 latest ai news\"\n",
    "config = {\"configurable\": {\"thread_id\": 1}}\n",
    "\n",
    "response = graph_builder.invoke({\"messages\": query}, config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5263feb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.1-8b-instant` in organization `org_01k66286qyeesr19q9k4xxa0bg` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 8397, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m query=\u001b[33m\"\u001b[39m\u001b[33mgive one more news about same topic\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mgraph_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      6\u001b[39m     message.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mmodel_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_node\u001b[39m(state:State):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mtools_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5548\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5541\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5542\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5543\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5546\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5547\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5551\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:398\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     **kwargs: Any,\n\u001b[32m    392\u001b[39m ) -> AIMessage:\n\u001b[32m    393\u001b[39m     config = ensure_config(config)\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    395\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    396\u001b[39m         cast(\n\u001b[32m    397\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    408\u001b[39m         ).message,\n\u001b[32m    409\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1117\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1108\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1110\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1114\u001b[39m     **kwargs: Any,\n\u001b[32m   1115\u001b[39m ) -> LLMResult:\n\u001b[32m   1116\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:927\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    926\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m927\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m         )\n\u001b[32m    934\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    935\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1221\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1219\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1225\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:590\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    585\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    586\u001b[39m params = {\n\u001b[32m    587\u001b[39m     **params,\n\u001b[32m    588\u001b[39m     **kwargs,\n\u001b[32m    589\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:461\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    243\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    301\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.1-8b-instant` in organization `org_01k66286qyeesr19q9k4xxa0bg` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 8397, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
      "During task with name 'model_node' and id '489b6acd-cd89-9755-298f-fc3d9a902ddc'"
     ]
    }
   ],
   "source": [
    "query=\"give one more news about same topic\"\n",
    "config = {\"configurable\": {\"thread_id\": 1}}\n",
    "\n",
    "response = graph_builder.invoke({\"messages\": query}, config=config)\n",
    "for message in response['messages']:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGs In Depth (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
