{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea74e95",
   "metadata": {},
   "source": [
    "### Building RAG System with LangChain and FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4341e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\RAGs In Depth\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#importing libraries\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#langchain imports\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5b348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Machine Learning', 'page': 1, 'topic': 'AI'}, page_content='\\nMachine learning is a branch of artificial intelligence that enables computers to learn from data and improve performance without being explicitly programmed. \\nIt works by feeding large datasets into algorithms that identify patterns and relationships, which can then be used to make predictions or decisions on new, unseen data. \\nUnlike traditional programming, where rules must be manually defined, machine learning systems adapt and evolve as they encounter more information. \\nThis makes them especially powerful for complex tasks such as image recognition, speech processing, natural language translation, fraud detection, and personalized recommendations. \\nBy leveraging techniques like supervised learning, unsupervised learning, and reinforcement learning, machine learning has become a cornerstone of modern technology, powering applications from healthcare diagnostics to self-driving cars\\n'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='\\n        Deep learning is a specialized branch of machine learning that uses multilayered neural networks to process and learn from complex data. It mimics the way the human brain works by stacking artificial neurons into layers, allowing computers to automatically discover intricate patterns and representations without manual feature engineering. The term �deep� refers to the use of many hidden layers�sometimes hundreds or thousands�that transform input data step by step until a meaningful output is produced. These architectures can be trained in supervised, semi-supervised, or unsupervised ways, making them highly versatile.\\nDeep learning has revolutionized fields such as computer vision, natural language processing, speech recognition, and autonomous systems. For example, convolutional neural networks (CNNs) excel at image classification, while recurrent and transformer-based networks dominate language tasks. By leveraging vast datasets and powerful GPUs, deep learning models achieve state-of-the-art performance in tasks ranging from facial recognition to self-driving cars. Its ability to handle unstructured data�like images, audio, and text�sets it apart from traditional machine learning approaches, making deep learning a cornerstone of modern artificial intelligence )\\n'),\n",
       " Document(metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='\\n         Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. It combines linguistics, computer science, and machine learning to bridge the gap between human communication and digital systems. NLP techniques allow machines to process text and speech, making it possible to perform tasks such as sentiment analysis, language translation, speech recognition, chatbots, and information retrieval. By breaking down language into components like syntax, semantics, and context, NLP systems can extract meaning and respond intelligently. Modern NLP relies heavily on deep learning models, such as transformers, which power applications like voice assistants, automated customer support, and large-scale text analysis. This technology is central to how humans interact naturally with machines today, making it one of the most impactful areas of AI.\\n')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data ingestion and documents\n",
    "\n",
    "sample_documents=[\n",
    "    Document(page_content='''\n",
    "Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve performance without being explicitly programmed. \n",
    "It works by feeding large datasets into algorithms that identify patterns and relationships, which can then be used to make predictions or decisions on new, unseen data. \n",
    "Unlike traditional programming, where rules must be manually defined, machine learning systems adapt and evolve as they encounter more information. \n",
    "This makes them especially powerful for complex tasks such as image recognition, speech processing, natural language translation, fraud detection, and personalized recommendations. \n",
    "By leveraging techniques like supervised learning, unsupervised learning, and reinforcement learning, machine learning has become a cornerstone of modern technology, powering applications from healthcare diagnostics to self-driving cars\n",
    "''', \n",
    "metadata={\"source\": \"Machine Learning\", \"page\": 1, \"topic\": \"AI\"}),\n",
    "\n",
    "Document(page_content='''\n",
    "        Deep learning is a specialized branch of machine learning that uses multilayered neural networks to process and learn from complex data. It mimics the way the human brain works by stacking artificial neurons into layers, allowing computers to automatically discover intricate patterns and representations without manual feature engineering. The term �deep� refers to the use of many hidden layers�sometimes hundreds or thousands�that transform input data step by step until a meaningful output is produced. These architectures can be trained in supervised, semi-supervised, or unsupervised ways, making them highly versatile.\n",
    "Deep learning has revolutionized fields such as computer vision, natural language processing, speech recognition, and autonomous systems. For example, convolutional neural networks (CNNs) excel at image classification, while recurrent and transformer-based networks dominate language tasks. By leveraging vast datasets and powerful GPUs, deep learning models achieve state-of-the-art performance in tasks ranging from facial recognition to self-driving cars. Its ability to handle unstructured data�like images, audio, and text�sets it apart from traditional machine learning approaches, making deep learning a cornerstone of modern artificial intelligence )\n",
    "''',\n",
    "metadata={\"source\": \"Deep Learning\", \"page\": 1, \"topic\": \"AI\"}),\n",
    "\n",
    "Document(page_content='''\n",
    "         Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. It combines linguistics, computer science, and machine learning to bridge the gap between human communication and digital systems. NLP techniques allow machines to process text and speech, making it possible to perform tasks such as sentiment analysis, language translation, speech recognition, chatbots, and information retrieval. By breaking down language into components like syntax, semantics, and context, NLP systems can extract meaning and respond intelligently. Modern NLP relies heavily on deep learning models, such as transformers, which power applications like voice assistants, automated customer support, and large-scale text analysis. This technology is central to how humans interact naturally with machines today, making it one of the most impactful areas of AI.\n",
    "''',\n",
    "metadata={\"source\": \"Natural Language Processing\", \"page\": 1, \"topic\": \"AI\"})\n",
    "]\n",
    "\n",
    "sample_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88adbda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Machine Learning', 'page': 1, 'topic': 'AI'}, page_content='Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve performance without being explicitly programmed. \\nIt works by feeding large datasets into algorithms that identify patterns and relationships, which can then be used to make predictions or decisions on new, unseen data. \\nUnlike traditional programming, where rules must be manually defined, machine learning systems adapt and evolve as they encounter more information. \\nThis makes them'),\n",
       " Document(metadata={'source': 'Machine Learning', 'page': 1, 'topic': 'AI'}, page_content='they encounter more information. \\nThis makes them especially powerful for complex tasks such as image recognition, speech processing, natural language translation, fraud detection, and personalized recommendations. \\nBy leveraging techniques like supervised learning, unsupervised learning, and reinforcement learning, machine learning has become a cornerstone of modern technology, powering applications from healthcare diagnostics to self-driving cars'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='Deep learning is a specialized branch of machine learning that uses multilayered neural networks to process and learn from complex data. It mimics the way the human brain works by stacking artificial neurons into layers, allowing computers to automatically discover intricate patterns and representations without manual feature engineering. The term �deep� refers to the use of many hidden layers�sometimes hundreds or thousands�that transform input data step by step until a meaningful'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='input data step by step until a meaningful output is produced. These architectures can be trained in supervised, semi-supervised, or unsupervised ways, making them highly versatile.\\nDeep learning has revolutionized fields such as computer vision, natural language processing, speech recognition, and autonomous systems. For example, convolutional neural networks (CNNs) excel at image classification, while recurrent and transformer-based networks dominate language tasks. By leveraging vast'),\n",
       " Document(metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='dominate language tasks. By leveraging vast datasets and powerful GPUs, deep learning models achieve state-of-the-art performance in tasks ranging from facial recognition to self-driving cars. Its ability to handle unstructured data�like images, audio, and text�sets it apart from traditional machine learning approaches, making deep learning a cornerstone of modern artificial intelligence )'),\n",
       " Document(metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. It combines linguistics, computer science, and machine learning to bridge the gap between human communication and digital systems. NLP techniques allow machines to process text and speech, making it possible to perform tasks such as sentiment analysis, language translation, speech recognition, chatbots, and information'),\n",
       " Document(metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='speech recognition, chatbots, and information retrieval. By breaking down language into components like syntax, semantics, and context, NLP systems can extract meaning and respond intelligently. Modern NLP relies heavily on deep learning models, such as transformers, which power applications like voice assistants, automated customer support, and large-scale text analysis. This technology is central to how humans interact naturally with machines today, making it one of the most impactful areas'),\n",
       " Document(metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='today, making it one of the most impactful areas of AI.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text splitting\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    separators=[\" \"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(sample_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31dff05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 8 chunks from 3 documents\n",
      "\n",
      "Example chunk:\n",
      "Content: Machine learning is a branch of artificial intelligence that enables computers to learn from data and improve performance without being explicitly programmed. \n",
      "It works by feeding large datasets into algorithms that identify patterns and relationships, which can then be used to make predictions or decisions on new, unseen data. \n",
      "Unlike traditional programming, where rules must be manually defined, machine learning systems adapt and evolve as they encounter more information. \n",
      "This makes them\n",
      "Metadata: {'source': 'Machine Learning', 'page': 1, 'topic': 'AI'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created {len(chunks)} chunks from {len(sample_documents)} documents\")\n",
    "print(\"\\nExample chunk:\")\n",
    "print(f\"Content: {chunks[0].page_content}\")\n",
    "print(f\"Metadata: {chunks[0].metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1aef623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eedd3a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore created with 8 vectors\n"
     ]
    }
   ],
   "source": [
    "#vectorstore and retrievers\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"vectorstore created with {vectorstore.index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238691e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorstore saved in 'faiss_index' directory\n"
     ]
    }
   ],
   "source": [
    "#save vectorstore in local machine\n",
    "\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "print(\"vectorstore saved in 'faiss_index' directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b1e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load vectstore from local machine\n",
    "\n",
    "faiss_store = FAISS.load_local(\n",
    "    folder_path=\"faiss_index\",\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6a958b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='7ba2b890-01bc-4aae-8f82-7add5df85455', metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. It combines linguistics, computer science, and machine learning to bridge the gap between human communication and digital systems. NLP techniques allow machines to process text and speech, making it possible to perform tasks such as sentiment analysis, language translation, speech recognition, chatbots, and information'),\n",
       " Document(id='9d1ee29e-abef-4db7-a4ff-604c61ac9fa2', metadata={'source': 'Natural Language Processing', 'page': 1, 'topic': 'AI'}, page_content='speech recognition, chatbots, and information retrieval. By breaking down language into components like syntax, semantics, and context, NLP systems can extract meaning and respond intelligently. Modern NLP relies heavily on deep learning models, such as transformers, which power applications like voice assistants, automated customer support, and large-scale text analysis. This technology is central to how humans interact naturally with machines today, making it one of the most impactful areas')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similarity search\n",
    "\n",
    "query=\"what is NLP?\"\n",
    "results = faiss_store.similarity_search(query, k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1df131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: what is NLP?\n",
      "Top 2 similar chunks\n",
      "\n",
      "1. Source: Natural Language Processing\n",
      "  Content: Natural Language Processing (NLP) is a field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. It combines linguistics, computer scie...\n",
      "\n",
      "2. Source: Natural Language Processing\n",
      "  Content: speech recognition, chatbots, and information retrieval. By breaking down language into components like syntax, semantics, and context, NLP systems can extract meaning and respond intelligently. Moder...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(\"Top 2 similar chunks\")\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n{i+1}. Source: {doc.metadata['source']}\")\n",
    "    print(f\"  Content: {doc.page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8074e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='30ea8fb7-a012-484c-afa9-054d1d9d2c53', metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='input data step by step until a meaningful output is produced. These architectures can be trained in supervised, semi-supervised, or unsupervised ways, making them highly versatile.\\nDeep learning has revolutionized fields such as computer vision, natural language processing, speech recognition, and autonomous systems. For example, convolutional neural networks (CNNs) excel at image classification, while recurrent and transformer-based networks dominate language tasks. By leveraging vast'),\n",
       " Document(id='7d41daf7-3e03-4b11-84b8-a7f77cf00a9a', metadata={'source': 'Deep Learning', 'page': 1, 'topic': 'AI'}, page_content='Deep learning is a specialized branch of machine learning that uses multilayered neural networks to process and learn from complex data. It mimics the way the human brain works by stacking artificial neurons into layers, allowing computers to automatically discover intricate patterns and representations without manual feature engineering. The term �deep� refers to the use of many hidden layers�sometimes hundreds or thousands�that transform input data step by step until a meaningful')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#search wth meta data filtering\n",
    "\n",
    "filter_dict={\"source\":\"Deep Learning\"}\n",
    "filtered_results= faiss_store.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    "    filter=filter_dict\n",
    ")\n",
    "\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16f2c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000018C0A687C10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018C0A7E1450>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building RAG chain with LCEL\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\n",
    "    model=\"groq:llama-3.1-8b-instant\"\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d99acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt template\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\n",
    "    You are a question answering chatbot, answer given question only using context provided.\n",
    "    if question cannot be answered from given context, please say I don't know.\n",
    "    context: {context}\n",
    "    question: {input} ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f2e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever\n",
    "retriever = faiss_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "#format documents for a prompt\n",
    "def format_docs(docs:List[Document])->str:\n",
    "    \"format documents for insertion into prompt\"\n",
    "    formatted=[]\n",
    "    for i, doc in enumerate(docs):\n",
    "        source = doc.metadata.get('source', 'unknown')\n",
    "        formatted.append(f\"Document {i+1} (source: {source}): \\n{doc.page_content}\")\n",
    "    return \"\\n\\n\".join(formatted) \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "558ab7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000018C08C347D0>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template=\"\\n    You are a question answering chatbot, answer given question only using context provided.\\n    if question cannot be answered from given context, please say I don't know.\\n    context: {context}\\n    question: {input} \"), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000018C0A687C10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018C0A7E1450>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_rag_chain =(\n",
    "    {\"context\": retriever | RunnableLambda(format_docs),\n",
    "     \"question\": RunnablePassthrough()}\n",
    "     | prompt\n",
    "     | model\n",
    "     | StrOutputParser()\n",
    ") \n",
    "\n",
    "simple_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72f88c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018C36FFBC40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant, Use the provided context to answer questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Context: {context}\\n\\n Question: {input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Conversationl Rag Chain\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant, Use the provided context to answer questions.\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"user\", \"Context: {context}\\n\\n Question: {input}\")\n",
    "])\n",
    "\n",
    "conversational_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "587c93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: format_docs(retriever.invoke(x['input'])))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000018C36FFBC40>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful AI assistant, Use the provided context to answer questions.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template='Context: {context}\\n\\n Question: {input}'), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000018C0A687C10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018C0A7E1450>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_conversational_rag():\n",
    "    \"create a conversational rag chain with memory\"\n",
    "    return(\n",
    "        RunnablePassthrough.assign(\n",
    "            context=lambda x : format_docs(retriever.invoke(x[\"input\"]))\n",
    "        )\n",
    "        | conversational_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "conversational_rag=create_conversational_rag()\n",
    "\n",
    "conversational_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43857046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000018C08C347D0>, search_kwargs={})\n",
       "           | RunnableLambda(format_docs),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, template=\"\\n    You are a question answering chatbot, answer given question only using context provided.\\n    if question cannot be answered from given context, please say I don't know.\\n    context: {context}\\n    question: {input} \"), additional_kwargs={})])\n",
       "| ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000018C0A687C10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018C0A7E1450>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#streaming rag chain\n",
    "streaming_rag_chain = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model \n",
    ")\n",
    "\n",
    "streaming_rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e1e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function for different chain types\n",
    "\n",
    "def test_rag_chains(question:str):\n",
    "    \"Test all RAG chain variants\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    #1. Simple RAG\n",
    "    print(\"\\n1. Simple RAG Chain:\")\n",
    "    answer = simple_rag_chain.invoke({\"input\":question})\n",
    "    print(f\"Answer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd325583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is ml?\n",
      "============================================================\n",
      "\n",
      "1. Simple RAG Chain:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_rag_chains\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is ml?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtest_rag_chains\u001b[39m\u001b[34m(question)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#1. Simple RAG\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m1. Simple RAG Chain:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m answer = \u001b[43msimple_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3141\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3139\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3141\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3142\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3143\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3867\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3862\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3863\u001b[39m         futures = [\n\u001b[32m   3864\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3865\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3866\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3867\u001b[39m         output = \u001b[43m{\u001b[49m\n\u001b[32m   3868\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3869\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3870\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   3871\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3872\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3868\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   3862\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3863\u001b[39m         futures = [\n\u001b[32m   3864\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3865\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3866\u001b[39m         ]\n\u001b[32m   3867\u001b[39m         output = {\n\u001b[32m-> \u001b[39m\u001b[32m3868\u001b[39m             key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3869\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures, strict=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   3870\u001b[39m         }\n\u001b[32m   3871\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3872\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3851\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3845\u001b[39m child_config = patch_config(\n\u001b[32m   3846\u001b[39m     config,\n\u001b[32m   3847\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3848\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3849\u001b[39m )\n\u001b[32m   3850\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3851\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3853\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchild_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3855\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3141\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3139\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3140\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3141\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3142\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3143\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:216\u001b[39m, in \u001b[36mBaseRetriever.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    214\u001b[39m kwargs_ = kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_arg_supported:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    220\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._get_relevant_documents(\u001b[38;5;28minput\u001b[39m, **kwargs_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:1040\u001b[39m, in \u001b[36mVectorStoreRetriever._get_relevant_documents\u001b[39m\u001b[34m(self, query, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1038\u001b[39m kwargs_ = \u001b[38;5;28mself\u001b[39m.search_kwargs | kwargs\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvectorstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.search_type == \u001b[33m\"\u001b[39m\u001b[33msimilarity_score_threshold\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1042\u001b[39m     docs_and_similarities = (\n\u001b[32m   1043\u001b[39m         \u001b[38;5;28mself\u001b[39m.vectorstore.similarity_search_with_relevance_scores(\n\u001b[32m   1044\u001b[39m             query, **kwargs_\n\u001b[32m   1045\u001b[39m         )\n\u001b[32m   1046\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:643\u001b[39m, in \u001b[36mFAISS.similarity_search\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search\u001b[39m(\n\u001b[32m    624\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    625\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    629\u001b[39m     **kwargs: Any,\n\u001b[32m    630\u001b[39m ) -> List[Document]:\n\u001b[32m    631\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    632\u001b[39m \n\u001b[32m    633\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    641\u001b[39m \u001b[33;03m        List of Documents most similar to the query.\u001b[39;00m\n\u001b[32m    642\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     docs_and_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfetch_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:515\u001b[39m, in \u001b[36mFAISS.similarity_search_with_score\u001b[39m\u001b[34m(self, query, k, filter, fetch_k, **kwargs)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimilarity_search_with_score\u001b[39m(\n\u001b[32m    492\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    493\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    497\u001b[39m     **kwargs: Any,\n\u001b[32m    498\u001b[39m ) -> List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    499\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[32m    500\u001b[39m \n\u001b[32m    501\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    513\u001b[39m \u001b[33;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[32m    514\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m     embedding = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m     docs = \u001b[38;5;28mself\u001b[39m.similarity_search_with_score_by_vector(\n\u001b[32m    517\u001b[39m         embedding,\n\u001b[32m    518\u001b[39m         k,\n\u001b[32m   (...)\u001b[39m\u001b[32m    521\u001b[39m         **kwargs,\n\u001b[32m    522\u001b[39m     )\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:266\u001b[39m, in \u001b[36mFAISS._embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) -> List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.embedding_function, Embeddings):\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embedding_function(text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:172\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.embed_query\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    159\u001b[39m \n\u001b[32m    160\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \n\u001b[32m    166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m embed_kwargs = (\n\u001b[32m    168\u001b[39m     \u001b[38;5;28mself\u001b[39m.query_encode_kwargs\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.query_encode_kwargs) > \u001b[32m0\u001b[39m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encode_kwargs\n\u001b[32m    171\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:124\u001b[39m, in \u001b[36mHuggingFaceEmbeddings._embed\u001b[39m\u001b[34m(self, texts, encode_kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed a text using the HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m texts = \u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    126\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m._client.start_multi_process_pool()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\RAGs In Depth\\.venv\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:124\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Embed a text using the HuggingFace transformer model.\u001b[39;00m\n\u001b[32m    111\u001b[39m \n\u001b[32m    112\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m texts = [\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.multi_process:\n\u001b[32m    126\u001b[39m     pool = \u001b[38;5;28mself\u001b[39m._client.start_multi_process_pool()\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "test_rag_chains(\"what is ml?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5f2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAGs In Depth (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
